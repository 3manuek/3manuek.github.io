<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Import data from Redshift into Clickhouse in a single command. | tr3sma</title><meta name=description content><meta property="og:title" content="Import data from Redshift into Clickhouse in a single command."><meta property="og:description" content="Scope If you heard about Clickhouse and you are wondering how to test with your residing data in Redshift, here is a command that will show you a few tips to make you speed up.
Update (July 4th): There is a serie of posts about Clickhouse vs Redshift comparisons, the first post is this one.
The standard wat to move your data out of Redshift is by using UNLOAD command, which pushes the output into S3 files."><meta property="og:type" content="article"><meta property="og:url" content="/blog/2017-03/import-data-to-ch-from-rs/"><meta property="og:image" content="/blog/assets/thumbnail_db.png"><meta property="og:image" content="/blog/assets/tachyons-logo-script-feature.png"><meta property="article:published_time" content="2017-03-06T00:00:00+00:00"><meta property="article:modified_time" content="2017-03-06T00:00:00+00:00"><meta itemprop=name content="Import data from Redshift into Clickhouse in a single command."><meta itemprop=description content="Scope If you heard about Clickhouse and you are wondering how to test with your residing data in Redshift, here is a command that will show you a few tips to make you speed up.
Update (July 4th): There is a serie of posts about Clickhouse vs Redshift comparisons, the first post is this one.
The standard wat to move your data out of Redshift is by using UNLOAD command, which pushes the output into S3 files."><meta itemprop=datePublished content="2017-03-06T00:00:00+00:00"><meta itemprop=dateModified content="2017-03-06T00:00:00+00:00"><meta itemprop=wordCount content="1091"><meta itemprop=image content="/blog/assets/thumbnail_db.png"><meta itemprop=image content="/blog/assets/tachyons-logo-script-feature.png"><meta itemprop=keywords content="hugo-site,"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="/blog/assets/thumbnail_db.png"><meta name=twitter:title content="Import data from Redshift into Clickhouse in a single command."><meta name=twitter:description content="Scope If you heard about Clickhouse and you are wondering how to test with your residing data in Redshift, here is a command that will show you a few tips to make you speed up.
Update (July 4th): There is a serie of posts about Clickhouse vs Redshift comparisons, the first post is this one.
The standard wat to move your data out of Redshift is by using UNLOAD command, which pushes the output into S3 files."><meta name=twitter:site content="@3manuek"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','G-GY0KSNNSTL','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><!--[if IE]><script src=//html5shiv.googlecode.com/svn/trunk/html5.js></script><![endif]--><link rel="shortcut icon" href="/img/favicon.ico?v=0" type=image/x-icon><link rel=icon href="/img/favicon.ico?v=0" type=image/x-icon><link rel=stylesheet href=/style.main.min.af051a891b2af29b5e832059f2d65564f8acece3291dcaca54df6ef06e3e084e.css integrity="sha256-rwUaiRsq8ptegyBZ8tZVZPis7OMpHcrKVN9u8G4+CE4=" media=screen></head><body><div class="grid-container single"><header class="site-header pa4 bb b--transparent" role=banner><nav class="site-nav db dt-l w-100" role=nav><a class="site-brand db dtc-l v-mid link no-underline w-100 w-33-l tc tl-l" href=/ title=Home><img src=/img/firma.png class="dib db-l h2 w-auto" alt=tr3sma></a><div class="site-links db dtc-l v-mid w-100 w-47-l tc tr-l mt3 mt0-l"><a class="link f6 f5-l dib pv1 ph2" href=/ title="Home Page">Home</a>
<a class="link f6 f5-l dib pv1 ph2" href=/about/ title="About tr3sma">About</a>
<a class="link f6 f5-l dib pv1 ph2" href=/blog/ title=Blog>Blog</a>
<a class="link f6 f5-l dib pv1 ph2" href=/contact/ title="Contact Form">Contact</a></div></nav></header><main class="page-main pa4" role=main><section class="page-content mw7 center"><article class="post-content pa0 ph4-l"><header class=post-header><h1 class="f2 f1-m f-subheadline-l fw5-ns mv4 lh-solid tracked-tight">Import data from Redshift into Clickhouse in a single command.</h1><h2 class="f7 fw7 measure mv0 ttu tracked">Importing and explaning the process.</h2><p class="f6 measure lh-copy mv1">By 3manuek in <a href=/categories/theme-features>Theme Features</a></p><p class="f7 db mv0 ttu">March 6, 2017</p></header><section class="post-body pt5 pb4"><h2 id=scope>Scope</h2><p>If you heard about Clickhouse and you are wondering how to test with your residing data in Redshift, here is a command
that will show you a few tips to make you speed up.</p><p>Update (July 4th): There is a serie of posts about Clickhouse vs Redshift comparisons, the first post is <a href=https://www.altinity.com/blog/2017/6/20/clickhouse-vs-redshift>this one</a>.</p><p>The standard wat to move your data out of Redshift is by using <a href=http://docs.aws.amazon.com/redshift/latest/dg/r_UNLOAD.html>UNLOAD</a> command,
which pushes the output into S3 files. Not surprisingly, Redshift does not support
<code>COPY (&lt;query>) TO STDOUT</code>, which could make life easier (as it
Postgres version 8.0.2 based, quite ol&rsquo;). Info about this, <a href=http://docs.aws.amazon.com/redshift/latest/dg/r_COPY.html>here</a>.</p><p>Clickhouse supports several engines but so far, you will for sure start with MergeTree. The supported types are more finite,
although they should be enough for plain analytics. It&rsquo;s recommended to add sampling support at table
creation, in the engine parameters through corresponding hash function with the column type that <em>return unsigned integers</em> after the key definition.
In this case I&rsquo;ve choosen cityHash64 as it is not cryptographic, it has a decent accuracy and better performance.</p><p>The table in CH is the following:</p><div class=highlight><div style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">7
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">8
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=color:#007020;font-weight:700>CREATE</span> <span style=color:#007020;font-weight:700>TABLE</span> thenewdb.thetable (
normdate <span style=color:#007020>Date</span>,
id String,
datefield DateTime,
(... many others ...)
<span style=color:#007020;font-weight:700>data</span> String
)
ENGINE <span style=color:#666>=</span> MergeTree(normdate,cityHash64(id), (datefield, id,cityHash64(id)),<span style=color:#40a070>8192</span>);
</code></pre></td></tr></table></div></div><blockquote><p>NOTE: The engine parameters are: a date column, the optional sampling expression (cityHash64)
the primary key (datefield,id) and the index granularity.</p></blockquote><p>The table in Redshift is:</p><div class=highlight><div style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">7
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">8
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql>     <span style=color:#007020;font-weight:700>Column</span>     <span style=color:#666>|</span>            <span style=color:#007020;font-weight:700>Type</span>             <span style=color:#666>|</span> Modifiers
<span style=color:#60a0b0;font-style:italic>----------------+-----------------------------+-----------
</span><span style=color:#60a0b0;font-style:italic></span> id             <span style=color:#666>|</span> <span style=color:#007020>character</span> <span style=color:#007020>varying</span>(<span style=color:#40a070>32</span>)       <span style=color:#666>|</span> <span style=color:#007020;font-weight:700>not</span> <span style=color:#007020;font-weight:700>null</span>
 datefield      <span style=color:#666>|</span> <span style=color:#007020;font-weight:700>timestamp</span> <span style=color:#007020;font-weight:700>without</span> time <span style=color:#007020;font-weight:700>zone</span> <span style=color:#666>|</span> <span style=color:#007020;font-weight:700>not</span> <span style=color:#007020;font-weight:700>null</span>
 (... other columns...)
  <span style=color:#007020;font-weight:700>data</span>           <span style=color:#666>|</span> <span style=color:#007020>character</span> <span style=color:#007020>varying</span>(<span style=color:#40a070>8192</span>)     <span style=color:#666>|</span>
Indexes:
    <span style=color:#4070a0>&#34;</span><span style=color:#4070a0>thetable_pkey1</span><span style=color:#4070a0>&#34;</span> <span style=color:#007020;font-weight:700>PRIMARY</span> <span style=color:#007020;font-weight:700>KEY</span>, btree (id)
</code></pre></td></tr></table></div></div><p>ClickHouse requires a Date column, which ends up to be an additional
column in your table structure. For more information,
check out the <a href=https://clickhouse.yandex/reference_en.html#MergeTree>MergeTree doc</a>.</p><h2 id=the-magic>The magic</h2><ul><li><p>Open a screen/ tmux session.</p></li><li><p>Execute the command:</p></li></ul><div class=highlight><div style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#007020>time</span> psql -h rs1.garbagestring.redshift.amazonaws.com <span style=color:#4070a0;font-weight:700>\
</span><span style=color:#4070a0;font-weight:700></span>          -p <span style=color:#40a070>5439</span> -U redshift thedatabase <span style=color:#4070a0;font-weight:700>\
</span><span style=color:#4070a0;font-weight:700></span>          -Antq --variable<span style=color:#666>=</span><span style=color:#4070a0>&#34;FETCH_COUNT=1000000&#34;</span> -F <span style=color:#4070a0>$&#39;\t&#39;</span> <span style=color:#4070a0>&lt;&lt;EOF | \
</span><span style=color:#4070a0>          clickhouse-client --database thenewdb --query=&#34;INSERT INTO thenewdb.thetable FORMAT TabSeparated&#34;
</span><span style=color:#4070a0>select trunc(datefield),
</span><span style=color:#4070a0>  id,
</span><span style=color:#4070a0>  datefield::timestamp(0) ,
</span><span style=color:#4070a0>  store_id ,
</span><span style=color:#4070a0>(... many columns more ... )
</span><span style=color:#4070a0>  regexp_replace(data,&#39;\\t|\\n&#39;,&#39;&#39;) 
</span><span style=color:#4070a0>from theoriginaltable
</span><span style=color:#4070a0>EOF</span>
</code></pre></td></tr></table></div></div><h2 id=calculation-of-ram>Calculation of RAM</h2><p><code>MergeTree</code> engine is indeed an interesting implementation. It is not an LSM as it
does not process in <em>memtables</em> nor neither <em>log</em>. It process the data in batches and write
directly to the file system, consuming a significant amount of RAM at the cost
of saving disk operations (and occasionally CPU cycles) by background workers that do the merges.</p><p>A common error when you run out of memory due to this merge processes eating RAM is:</p><pre><code>Code: 240. DB::Exception: Allocator: 
Cannot mremap., errno: 12, strerror: Cannot allocate memory
</code></pre><p>The reason on why this happens is due to the RAM consumed on background merges.
There are five elements to have in mind in order to calculate the needed memory:</p><ul><li><code>background_pool_size</code> is 6, determining the maximum number of background merges.</li><li>Maximum number of merge pieces during merge (default 100)</li><li>block size for the merger (8192 rows)</li><li>average size of row uncompressed</li><li>maximum overhead memory allocation for buffers (2)</li></ul><p>You can assume a row size of 1024 bytes and multiply all of the above
together. i.e. <code>SELECT formatReadableSize( 2* 6 * 100 * 8192 * 1024);</code></p><p>The current issue is that the merge algorithm process by row instead each
column separately, and is expected to have a performance gain. You can try
the <em>vertical algorithm</em> by setting <code>enable_vertical_merge_algorithm</code> in the
configuration file.</p><p>So, guessing that you get a row size of <code>13557 bytes (14k)</code> measured using query 1),
you can get an approximate of RAM needed for the block of operations 2).</p><ol><li></li></ol><pre><code>time psql -h rs-clusterandhash.us-east-1.redshift.amazonaws.com\
 -p 5439 -U redshift reportdb  -Antq --variable=&quot;FETCH_COUNT=1000000&quot; -F $'\t' &lt;&lt;EOF | wc -c
select
  *
from big_table
LIMIT 1
EOF
13835
</code></pre><ol start=2><li></li></ol><pre><code>SELECT formatReadableSize((((2 * 6) * 100) * 8192) * 13557)
┌─formatReadableSize(multiply(multiply(multiply(multiply(2, 6), 100), 8192), 13557))─┐
│ 124.12 GiB                                                                         │
└────────────────────────────────────────────────────────────────────────────────────┘
</code></pre><p>More information on this <a href=https://groups.google.com/forum/#!topic/clickhouse/SLlMNwIOtmY>google groups thread</a>.</p><p>Unfortunately, client can&rsquo;t handle this properly yet. Even limiting the memory usage
with <code>--max_memory_usage 5GB</code> (i.e), you will get a different error like this:</p><pre><code>Code: 241. DB::Exception: 
Received from localhost:9000, 127.0.0.1. 
DB::Exception: Memory limit (for query) exceeded: 
would use 1.00 MiB (attempt to allocate chunk of 1048576 bytes), maximum: 5.00 B.
</code></pre><p>If the necessary RAM is very close to your current resource, a possible solution would be using <code>ReplacingMergeTree</code> engine,
but deduplication is not warranted and indeed you will play in very small limits (you should be
very close to the above calculation).
Also, there are several settings at engine level for tuning the mergetree engine through configuration
at <a href=https://github.com/yandex/ClickHouse/blob/9de4d8facb412fa178cd8380a4411c30da43acc7/dbms/src/Storages/MergeTree/MergeTreeSettings.h>MergeTreeSettings.h</a></p><p>i.e., the bellow will reduce the RAM consumption considerably, at a cost of reducing
durability and changing merge algorithm:</p><pre><code>    &lt;merge_tree&gt;
        &lt;max_suspicious_broken_parts&gt;20&lt;/max_suspicious_broken_parts&gt;
        &lt;enable_vertical_merge_algorithm&gt;1&lt;/enable_vertical_merge_algorithm&gt;
        &lt;max_delay_to_insert&gt;5&lt;/max_delay_to_insert&gt;
        &lt;parts_to_delay_insert&gt;100&lt;/parts_to_delay_insert&gt;
    &lt;/merge_tree&gt;
</code></pre><h2 id=the-explanation>The explanation</h2><ul><li>Why TabSeparated?</li></ul><p>Clickhouse offers several input/output <a href=https://clickhouse.yandex/reference_en.html#Formats>formats</a>, a lot.
Even tho, the tab in this case seemed enough for importing plain
texts (until a magic JSON with tabs and newlines broke the import).</p><ul><li>Why casting with no microseconds <code>::timestamp(0)</code>?</li></ul><p>CH does not support microseconds.</p><ul><li>Why doing replace <code>regexp_replace(data,'\\t|\\n','')</code>?</li></ul><p>We are importing using TSV, which by standard it does not
support newlines and obviously, tabs. Unfortunately, is
not possible at the moment to use enconding/decoding using
base64 for inserting without replacing (by streaming in the
data encoded and decode on fly by Clickhouse).</p><ul><li>Why <code>--variable="FETCH_COUNT=1000000"</code>?</li></ul><p>This is the sauce. <code>psql</code> will try to place the whole result
set in memory, making the box explode within a few minutes
after start running. Within this, it creates a server-side cursor, allowing us to import result set bigger than the client
machine.</p><ul><li>Why <code>-F $'\t'</code>?</li></ul><p>Depending on your shell, you may consider <a href=https://www.postgresql.org/message-id/455C54FE.5090902@numerixtechnology.de>this</a>. You need to use a <em>literal tab</em>,
which means that it needs to be the character itself. On UNIX
<code>Ctrl-V tab</code> should do the thing.</p><p>You can do a small try abuot this with <code>echo</code>. The option <code>-e</code>
<em>enables the interpretation of backslash escapes</em>. Also <code>printf</code>
is a clean option for printing special characters.</p><div class=highlight><div style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre style=background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ubuntu@host:~$ <span style=color:#007020>echo</span> <span style=color:#4070a0>$&#39;\n&#39;</span>

ubuntu@host:~$ <span style=color:#007020>echo</span> <span style=color:#4070a0>&#39;\n&#39;</span>
<span style=color:#4070a0;font-weight:700>\n</span>
ubuntu@host:~$ <span style=color:#007020>echo</span> -e <span style=color:#4070a0>&#39;\n&#39;</span>

</code></pre></td></tr></table></div></div><h2 id=rogue-numbers>Rogue numbers</h2><p>The process itself is consirably fast: it moved a 15GB table into a Clickhouse MergeTree of around 11GB in 20 minutes.</p><p>Instance details for RS: dc1.large 15GB RAM, vCPU 2, 2 nodes + 1 coordinator
Instance CH: single EC2 r4.2xlarge, volume 3000 iops EBS</p><p>I hope you find this tip useful!</p><details closed class="f6 fw7 input-reset"><dl class="f6 lh-copy"><dt class=fw7>Posted on:</dt><dd class="fw5 ml0">March 6, 2017</dd></dl><dl class="f6 lh-copy"><dt class=fw7>Length:</dt><dd class="fw5 ml0">6 minute read, 1091 words</dd></dl><dl class="f6 lh-copy"><dt class=fw7>Categories:</dt><dd class="fw5 ml0"><a href=/categories/theme-features>Theme Features</a></dd></dl><dl class="f6 lh-copy"><dt class=fw7>Series:</dt><dd class="fw5 ml0"><a href=/series/getting-started>Getting Started</a></dd></dl><dl class="f6 lh-copy"><dt class=fw7>Tags:</dt><dd class="fw5 ml0"><a href=/tags/hugo-site>hugo-site</a></dd></dl><dl class="f6 lh-copy"><dt class=fw7>See Also:</dt><dd class="fw5 ml0"><a href=/blog/2020-01/openlabs/>Open Labs</a></dd><dd class="fw5 ml0"><a href=/blog/2019-07/terraformwithpostgres/>What are the perks of using Postgres as a Terraform backend?</a></dd><dd class="fw5 ml0"><a href=/blog/2019-07/ansiblekubernetes/>Ansible and Kubernetes</a></dd></dl></details></section><footer class=post-footer><div class="post-pagination dt w-100 mt4 mb2"><a class="prev dtc pr2 tl v-top fw6" href=/blog/2017-03/fdw-overhead/>&larr; postgres_fdw estimated overhead</a>
<a class="next dtc pl2 tr v-top fw6" href=/blog/2019-06/clickhouse-sampling-data/>Clickhouse sampling on MergeTree engine. &rarr;</a></div></footer></article></section></main><footer class="site-footer pa4 bt b--transparent" role=contentinfo><nav class="db dt-l w-100"><p class="site-copyright f7 db dtc-l v-mid w-100 w-33-l tc tl-l pv2 pv0-l mv0 lh-copy">&copy; 2022 tr3sma, Madrid, Spain<br></p><div class="site-links f6 db dtc-l v-mid w-100 w-67-l tc tr-l pv2 pv0-l mv0"><a class="dib pv1 ph2 link" href=/index.xml title="RSS Feed">RSS</a></div></nav></footer></div></body></html>